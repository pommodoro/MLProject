\relax 
\citation{distill}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1}Definitions}{1}}
\citation{cnnvis}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.1}Feature Visualization:}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.2}Features:}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.3}Feature Map:}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.4}Weight Visualization:}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.5}Feature Map Visualization:}{2}}
\citation{zeiler}
\citation{oxford}
\citation{kvfrans}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.6}Deconvolutional Projection:}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}A Simple (But Useful) Example}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training set: 3,333 per category. Test set: 400 per category.  Train error: \nobreakspace  {}0 \%. Test error: \nobreakspace  {}0\%. Training time (black letters): 14 seconds. Training time (white letters): 21 seconds.\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:eflnetwork}{{1}{4}}
\citation{bengio}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Sample from EFL datset\relax }}{5}}
\newlabel{fig:eflsample}{{2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Trained weights of nodes $h_1$ and $h_1$. White pixels are close to 1, and black pixels are closest to 0. Clear signs of learning discriminant letter-features.\relax }}{5}}
\newlabel{fig:efl1}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces New trained weights for $h_1$ and $h_2$. Equally effective at classification but looking for different pattern. Note the black pixels in $h_2$ are not close to 0, they are very negative.\relax }}{6}}
\newlabel{fig:efl2}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces New "negative" samples of EFL\relax }}{6}}
\newlabel{fig:eflsample2}{{5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Weights visualization of negative dataset\relax }}{7}}
\newlabel{fig:mnistweights3}{{6}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2}MNIST: Deconvolutions and Feature Map}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Training set:55,000. Test set: 10,000. Training error: 2.4 \%. Test error: 2.79 \%. Total training time: 91 seconds\relax }}{7}}
\newlabel{fig:mnistnetwork}{{7}{7}}
\citation{resampling}
\citation{koman}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Random subset of filter weights\relax }}{8}}
\newlabel{fig:weightsmnist2}{{8}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Random subset of filter weights\relax }}{8}}
\newlabel{fig:weightsmnist1}{{9}{8}}
\citation{zeiler}
\citation{bengio}
\citation{kvfrans}
\citation{oxford}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Training set:\relax }}{10}}
\newlabel{fig:zeilerdeconv}{{10}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Node 1, Layer 1\relax }}{11}}
\newlabel{fig:node1layer1mnist}{{11}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Node 16, Layer 1\relax }}{11}}
\newlabel{fig:node16layer1mnist}{{12}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Node 22, Layer 1\relax }}{12}}
\newlabel{fig:node22layer1mnist}{{13}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Node 3, Layer 2\relax }}{12}}
\newlabel{fig:node3layer2mnist}{{14}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Node 32, Layer 2\relax }}{13}}
\newlabel{fig:node32layer2mnist}{{15}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Node 45, Layer 2\relax }}{13}}
\newlabel{fig:node45layer2mnist}{{16}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.1}Input optimization}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dog, Muffin or Fried Chicken?}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Training set: 8,071 (including rotated images). Test set: 896. Training error: 3.59 \%, Test error: 11.05 \%. Total training time: 924 seconds\relax }}{15}}
\newlabel{fig:dmcnetwork}{{17}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Node 8, Layer 1\relax }}{16}}
\newlabel{fig:node8layer1dmf}{{18}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Node 15, Layer 1\relax }}{17}}
\newlabel{fig:node15layer1dmf}{{19}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Node 23, Layer 1\relax }}{18}}
\newlabel{fig:node23layer1dmf}{{20}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Node 8, Layer 2\relax }}{19}}
\newlabel{fig:node8layer2dmf}{{21}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Node 15, Layer 2}}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces \relax }}{20}}
\newlabel{fig:node15layer2dmf}{{23}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Node 23, Layer 2\relax }}{21}}
\newlabel{fig:node23layer2dmf}{{24}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Node 8, Layer 3\relax }}{22}}
\newlabel{fig:node8layer3dmf}{{25}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Node 15, Layer 3\relax }}{23}}
\newlabel{fig:node15layer3dmf}{{26}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Node 23, Layer 3\relax }}{24}}
\newlabel{fig:node23layer3dmf}{{27}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces From left to right: layer-wide activation per layer measure as the F-norm\relax }}{25}}
\newlabel{fig:layeracts3}{{28}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces From left to right: layer-wide activation per layer measure as the F-norm\relax }}{25}}
\newlabel{fig:layeracts1}{{29}{25}}
\citation{distill}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion \& Further Work}{26}}
\citation{resampling}
\bibstyle{unsrt}
\bibdata{MLreferences}
\bibcite{distill}{1}
\bibcite{cnnvis}{2}
\bibcite{zeiler}{3}
\bibcite{oxford}{4}
\bibcite{kvfrans}{5}
\bibcite{bengio}{6}
\bibcite{resampling}{7}
\bibcite{koman}{8}
